ERROR: LoadError: MethodError: no method matching iterate(::Nothing)
Closest candidates are:
  iterate(!Matched::Union{LinRange, StepRangeLen}) at range.jl:664
  iterate(!Matched::Union{LinRange, StepRangeLen}, !Matched::Int64) at range.jl:664
  iterate(!Matched::T) where T<:Union{Base.KeySet{var"#s79", var"#s78"} where {var"#s79", var"#s78"<:Dict}, Base.ValueIterator{var"#s77"} where var"#s77"<:Dict} at dict.jl:693
  ...
Stacktrace:
  [1] indexed_iterate(I::Nothing, i::Int64)
    @ Base ./tuple.jl:89
  [2] MPS(A::ITensor{4}, sites::Vector{IndexSet{1, Index{Int64}, Tuple{Index{Int64}}}}; leftinds::Index{Int64}, orthocenter::Int64, kwargs::Base.Iterators.Pairs{Symbol, Any, NTuple{4, Symbol}, NamedTuple{(:ortho, :cutoff, :maxdim, :svd_alg), Tuple{String, Float64, Int64, String}}})
    @ ITensors ~/.julia/packages/ITensors/Ligbx/src/mps/abstractmps.jl:1388
  [3] setindex!(ψ::MPS, A::ITensor{4}, r::UnitRange{Int64}; orthocenter::Int64, perm::Vector{Int64}, kwargs::Base.Iterators.Pairs{Symbol, Any, NTuple{4, Symbol}, NamedTuple{(:ortho, :cutoff, :maxdim, :svd_alg), Tuple{String, Float64, Int64, String}}})
    @ ITensors ~/.julia/packages/ITensors/Ligbx/src/mps/abstractmps.jl:1328
  [4] setindex!(::MPS, ::ITensor{4}, ::UnitRange{Int64}, ::Pair{Symbol, Any}, ::Vararg{Pair{Symbol, Any}, N} where N; kwargs::Base.Iterators.Pairs{Symbol, Any, Tuple{Symbol, Symbol}, NamedTuple{(:orthocenter, :perm), Tuple{Int64, Vector{Int64}}}})
    @ ITensors ~/.julia/packages/ITensors/Ligbx/src/mps/abstractmps.jl:1340
  [5] swapbondsites(ψ::MPS, b::Int64; kwargs::Base.Iterators.Pairs{Symbol, Any, NTuple{4, Symbol}, NamedTuple{(:ortho, :cutoff, :maxdim, :svd_alg), Tuple{String, Float64, Int64, String}}})
    @ ITensors ~/.julia/packages/ITensors/Ligbx/src/mps/abstractmps.jl:1419
  [6] movesite(ψ::MPS, n1n2::Pair{Int64, Int64}; orthocenter::Int64, kwargs::Base.Iterators.Pairs{Symbol, Any, Tuple{Symbol, Symbol, Symbol}, NamedTuple{(:cutoff, :maxdim, :svd_alg), Tuple{Float64, Int64, String}}})
    @ ITensors ~/.julia/packages/ITensors/Ligbx/src/mps/abstractmps.jl:1447
  [7] _movesites(ψ::MPS, ns::Vector{Int64}, ns′::Vector{Int64}; kwargs::Base.Iterators.Pairs{Symbol, Any, Tuple{Symbol, Symbol, Symbol}, NamedTuple{(:cutoff, :maxdim, :svd_alg), Tuple{Float64, Int64, String}}})
    @ ITensors ~/.julia/packages/ITensors/Ligbx/src/mps/abstractmps.jl:1474
  [8] movesites(ψ::MPS, nsns′::Vector{Pair{Int64, Int64}}; kwargs::Base.Iterators.Pairs{Symbol, Any, Tuple{Symbol, Symbol, Symbol}, NamedTuple{(:cutoff, :maxdim, :svd_alg), Tuple{Float64, Int64, String}}})
    @ ITensors ~/.julia/packages/ITensors/Ligbx/src/mps/abstractmps.jl:1495
  [9] product(o::ITensor{4}, ψ::MPS, ns::Vector{Int64}; move_sites_back::Bool, apply_dag::Bool, kwargs::Base.Iterators.Pairs{Symbol, Any, Tuple{Symbol, Symbol, Symbol}, NamedTuple{(:cutoff, :maxdim, :svd_alg), Tuple{Float64, Int64, String}}})
    @ ITensors ~/.julia/packages/ITensors/Ligbx/src/mps/abstractmps.jl:1548
 [10] product(As::Vector{ITensor}, ψ::MPS; move_sites_back::Bool, kwargs::Base.Iterators.Pairs{Symbol, Any, Tuple{Symbol, Symbol, Symbol}, NamedTuple{(:cutoff, :maxdim, :svd_alg), Tuple{Float64, Int64, String}}})
    @ ITensors ~/.julia/packages/ITensors/Ligbx/src/mps/abstractmps.jl:1650
 [11] runcircuit(M::MPS, circuit_tensors::Vector{ITensor}; apply_dag::Nothing, cutoff::Float64, maxdim::Int64, svd_alg::String, move_sites_back::Bool, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
    @ PastaQ ~/.julia/packages/PastaQ/9VxGO/src/circuits/runcircuit.jl:86
 [12] #runcircuit#99
    @ ~/.julia/packages/PastaQ/9VxGO/src/circuits/runcircuit.jl:188 [inlined]
 [13] SurfCirc(dz::Int64, dx::Int64, nr::Int64, PEZ::Matrix{Int64}, PEX::Matrix{Int64}, Synz::Matrix{Int64}, Synx::Matrix{Int64}, zsch::Vector{Any}, xsch::Vector{Any}, bsch::Array{Int64, 3}, layout::Vector{Any}, ql::Matrix{Int64}, zl::Vector{Int64}, xl::Vector{Int64}, p::Float64, al2::Int64, tmeas::Float64, k2::Float64, nth::Int64, pmz::Float64, pmx::Float64, acc::Float64, bd::Int64)
    @ Main /shared/MLSurface/JuliaCLTNDecoder/experiment/d7/2e5/supp/suppagain/more/mlsurfnc.jl:1337
 [14] macro expansion
    @ /shared/MLSurface/JuliaCLTNDecoder/experiment/d7/2e5/supp/suppagain/more/mlsurfnc.jl:1432 [inlined]
 [15] macro expansion
    @ ./timing.jl:287 [inlined]
 [16] SurfMC(dz::Int64, dx::Int64, nr::Int64, p::Float64, al2::Int64, tmeas::Float64, k2::Float64, nth::Int64, acc::Float64, bd::Int64, err::Float64, nt::Int64; sim_id::Int64)
    @ Main /shared/MLSurface/JuliaCLTNDecoder/experiment/d7/2e5/supp/suppagain/more/mlsurfnc.jl:1431
 [17] top-level scope
    @ /shared/MLSurface/JuliaCLTNDecoder/experiment/d7/2e5/supp/suppagain/more/mlsurfnc.jl:1514
in expression starting at /shared/MLSurface/JuliaCLTNDecoder/experiment/d7/2e5/supp/suppagain/more/mlsurfnc.jl:1512
mu is
0.0
number of trials is
200
number of Z or Y failures is
0
number of X failures is
0
average trial time
1.5469050752499995
mu is
0.0
number of trials is
400
number of Z or Y failures is
0
number of X failures is
0
average trial time
2.917785455165001
mu is
0.0
number of trials is
600
number of Z or Y failures is
0
number of X failures is
0
average trial time
4.316200227940002
mu is
0.0
number of trials is
800
number of Z or Y failures is
0
number of X failures is
0
average trial time
5.703357919275005
mu is
0.0
number of trials is
1000
number of Z or Y failures is
0
number of X failures is
0
average trial time
7.068350469280005
mu is
0.0
number of trials is
1200
number of Z or Y failures is
0
number of X failures is
0
average trial time
8.442628842685004
mu is
0.0
number of trials is
1400
number of Z or Y failures is
0
number of X failures is
0
average trial time
9.821894849610002
mu is
0.0
number of trials is
1600
number of Z or Y failures is
0
number of X failures is
0
average trial time
11.219446031500006
mu is
0.0
number of trials is
1800
number of Z or Y failures is
0
number of X failures is
0
average trial time
12.624106373735014
mu is
0.0
number of trials is
2000
number of Z or Y failures is
0
number of X failures is
0
average trial time
14.039139755190018
mu is
0.0
number of trials is
2200
number of Z or Y failures is
0
number of X failures is
0
average trial time
15.488340240275008
mu is
0.0
number of trials is
2400
number of Z or Y failures is
0
number of X failures is
0
average trial time
16.939762059480028
mu is
0.0
number of trials is
2600
number of Z or Y failures is
0
number of X failures is
0
average trial time
18.40633170602503
mu is
0.0
number of trials is
2800
number of Z or Y failures is
0
number of X failures is
0
average trial time
19.90569248249003
mu is
0.0
number of trials is
3000
number of Z or Y failures is
0
number of X failures is
0
average trial time
21.411971420590035
mu is
0.0
number of trials is
3200
number of Z or Y failures is
0
number of X failures is
0
average trial time
22.955031172400048
mu is
0.0
number of trials is
3400
number of Z or Y failures is
0
number of X failures is
0
average trial time
24.51206732317006
mu is
0.0
number of trials is
3600
number of Z or Y failures is
0
number of X failures is
0
average trial time
26.094710149075055
mu is
0.0
number of trials is
3800
number of Z or Y failures is
0
number of X failures is
0
average trial time
27.69445869202005
mu is
0.0
number of trials is
4000
number of Z or Y failures is
0
number of X failures is
0
average trial time
29.305490572885063
mu is
0.0
number of trials is
4200
number of Z or Y failures is
0
number of X failures is
0
average trial time
30.90032352736507
mu is
0.0
number of trials is
4400
number of Z or Y failures is
0
number of X failures is
0
average trial time
32.52682175280006
mu is
0.0
number of trials is
4600
number of Z or Y failures is
0
number of X failures is
0
average trial time
34.164971806910046
mu is
0.0
number of trials is
4800
number of Z or Y failures is
0
number of X failures is
0
average trial time
35.80476358345506
mu is
0.0002
number of trials is
5000
number of Z or Y failures is
1
number of X failures is
0
average trial time
37.45340874193508
The SVD algorithm `"divide_and_conquer"` has thrown an error,
likely because of a convergance failure. You can try
other SVD algorithms that may converge better using the
`alg` (or `svd_alg` if called through `factorize` or MPS/MPO functionality) keyword argument:

 - "divide_and_conquer" is a divide-and-conquer algorithm
   (LAPACK's `gesdd`). It is fast, but may lead to some innacurate
   singular values for very ill-conditioned matrices.
   It also may sometimes fail to converge, leading to errors
   (in which case `"qr_iteration"` or `"recursive"` can be tried).

 - `"qr_iteration"` (LAPACK's `gesvd`) is typically slower 
   than "divide_and_conquer", especially for large matrices,
   but is more accurate for very ill-conditioned matrices 
   compared to `"divide_and_conquer"`.

 - `"recursive"` is ITensor's custom SVD algorithm. It is very
   reliable, but may be slow if high precision is needed.
   To get an `svd` of a matrix `A`, an eigendecomposition of
   ``A^{\dagger} A`` is used to compute `U` and then a `qr` of
   ``A^{\dagger} U`` is used to compute `V`. This is performed
   recursively to compute small singular values.

Returning `nothing`. For an output `F = svd(A, ...)` you can check if
`isnothing(F)` in your code and try a different algorithm.

To suppress this message in the future, you can wrap the `svd` call in the
`@suppress` macro from the `Suppressor` package.

