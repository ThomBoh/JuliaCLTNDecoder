ERROR: LoadError: MethodError: no method matching iterate(::Nothing)
Closest candidates are:
  iterate(!Matched::Union{LinRange, StepRangeLen}) at range.jl:664
  iterate(!Matched::Union{LinRange, StepRangeLen}, !Matched::Int64) at range.jl:664
  iterate(!Matched::T) where T<:Union{Base.KeySet{var"#s79", var"#s78"} where {var"#s79", var"#s78"<:Dict}, Base.ValueIterator{var"#s77"} where var"#s77"<:Dict} at dict.jl:693
  ...
Stacktrace:
  [1] indexed_iterate(I::Nothing, i::Int64)
    @ Base ./tuple.jl:89
  [2] MPS(A::ITensor{4}, sites::Vector{IndexSet{1, Index{Int64}, Tuple{Index{Int64}}}}; leftinds::Index{Int64}, orthocenter::Int64, kwargs::Base.Iterators.Pairs{Symbol, Any, NTuple{4, Symbol}, NamedTuple{(:ortho, :cutoff, :maxdim, :svd_alg), Tuple{String, Float64, Int64, String}}})
    @ ITensors ~/.julia/packages/ITensors/Ligbx/src/mps/abstractmps.jl:1388
  [3] setindex!(ψ::MPS, A::ITensor{4}, r::UnitRange{Int64}; orthocenter::Int64, perm::Vector{Int64}, kwargs::Base.Iterators.Pairs{Symbol, Any, NTuple{4, Symbol}, NamedTuple{(:ortho, :cutoff, :maxdim, :svd_alg), Tuple{String, Float64, Int64, String}}})
    @ ITensors ~/.julia/packages/ITensors/Ligbx/src/mps/abstractmps.jl:1328
  [4] setindex!(::MPS, ::ITensor{4}, ::UnitRange{Int64}, ::Pair{Symbol, Any}, ::Vararg{Pair{Symbol, Any}, N} where N; kwargs::Base.Iterators.Pairs{Symbol, Any, Tuple{Symbol, Symbol}, NamedTuple{(:orthocenter, :perm), Tuple{Int64, Vector{Int64}}}})
    @ ITensors ~/.julia/packages/ITensors/Ligbx/src/mps/abstractmps.jl:1340
  [5] swapbondsites(ψ::MPS, b::Int64; kwargs::Base.Iterators.Pairs{Symbol, Any, NTuple{4, Symbol}, NamedTuple{(:ortho, :cutoff, :maxdim, :svd_alg), Tuple{String, Float64, Int64, String}}})
    @ ITensors ~/.julia/packages/ITensors/Ligbx/src/mps/abstractmps.jl:1419
  [6] movesite(ψ::MPS, n1n2::Pair{Int64, Int64}; orthocenter::Int64, kwargs::Base.Iterators.Pairs{Symbol, Any, Tuple{Symbol, Symbol, Symbol}, NamedTuple{(:cutoff, :maxdim, :svd_alg), Tuple{Float64, Int64, String}}})
    @ ITensors ~/.julia/packages/ITensors/Ligbx/src/mps/abstractmps.jl:1447
  [7] _movesites(ψ::MPS, ns::Vector{Int64}, ns′::Vector{Int64}; kwargs::Base.Iterators.Pairs{Symbol, Any, Tuple{Symbol, Symbol, Symbol}, NamedTuple{(:cutoff, :maxdim, :svd_alg), Tuple{Float64, Int64, String}}})
    @ ITensors ~/.julia/packages/ITensors/Ligbx/src/mps/abstractmps.jl:1474
  [8] movesites(ψ::MPS, nsns′::Vector{Pair{Int64, Int64}}; kwargs::Base.Iterators.Pairs{Symbol, Any, Tuple{Symbol, Symbol, Symbol}, NamedTuple{(:cutoff, :maxdim, :svd_alg), Tuple{Float64, Int64, String}}})
    @ ITensors ~/.julia/packages/ITensors/Ligbx/src/mps/abstractmps.jl:1495
  [9] product(o::ITensor{4}, ψ::MPS, ns::Vector{Int64}; move_sites_back::Bool, apply_dag::Bool, kwargs::Base.Iterators.Pairs{Symbol, Any, Tuple{Symbol, Symbol, Symbol}, NamedTuple{(:cutoff, :maxdim, :svd_alg), Tuple{Float64, Int64, String}}})
    @ ITensors ~/.julia/packages/ITensors/Ligbx/src/mps/abstractmps.jl:1548
 [10] product(As::Vector{ITensor}, ψ::MPS; move_sites_back::Bool, kwargs::Base.Iterators.Pairs{Symbol, Any, Tuple{Symbol, Symbol, Symbol}, NamedTuple{(:cutoff, :maxdim, :svd_alg), Tuple{Float64, Int64, String}}})
    @ ITensors ~/.julia/packages/ITensors/Ligbx/src/mps/abstractmps.jl:1650
 [11] runcircuit(M::MPS, circuit_tensors::Vector{ITensor}; apply_dag::Nothing, cutoff::Float64, maxdim::Int64, svd_alg::String, move_sites_back::Bool, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})
    @ PastaQ ~/.julia/packages/PastaQ/9VxGO/src/circuits/runcircuit.jl:86
 [12] #runcircuit#99
    @ ~/.julia/packages/PastaQ/9VxGO/src/circuits/runcircuit.jl:188 [inlined]
 [13] SurfCirc(dz::Int64, dx::Int64, nr::Int64, PEZ::Matrix{Int64}, PEX::Matrix{Int64}, Synz::Matrix{Int64}, Synx::Matrix{Int64}, zsch::Vector{Any}, xsch::Vector{Any}, bsch::Array{Int64, 3}, layout::Vector{Any}, ql::Matrix{Int64}, zl::Vector{Int64}, xl::Vector{Int64}, p::Float64, al2::Int64, tmeas::Float64, k2::Float64, nth::Int64, pmz::Float64, pmx::Float64, acc::Float64, bd::Int64)
    @ Main /shared/JuliaCLTNDecoder/experiment/d9/7e5/mlsurfnc.jl:1337
 [14] macro expansion
    @ /shared/JuliaCLTNDecoder/experiment/d9/7e5/mlsurfnc.jl:1432 [inlined]
 [15] macro expansion
    @ ./timing.jl:287 [inlined]
 [16] SurfMC(dz::Int64, dx::Int64, nr::Int64, p::Float64, al2::Int64, tmeas::Float64, k2::Float64, nth::Int64, acc::Float64, bd::Int64, err::Float64, nt::Int64; sim_id::Int64)
    @ Main /shared/JuliaCLTNDecoder/experiment/d9/7e5/mlsurfnc.jl:1431
 [17] top-level scope
    @ /shared/JuliaCLTNDecoder/experiment/d9/7e5/mlsurfnc.jl:1514
in expression starting at /shared/JuliaCLTNDecoder/experiment/d9/7e5/mlsurfnc.jl:1512
mu is
0.0
number of trials is
200
number of Z or Y failures is
0
number of X failures is
0
average trial time
3.789298945424997
mu is
0.0025
number of trials is
400
number of Z or Y failures is
1
number of X failures is
0
average trial time
7.687336309544991
mu is
0.005
number of trials is
600
number of Z or Y failures is
3
number of X failures is
0
average trial time
11.865386249304986
mu is
0.00375
number of trials is
800
number of Z or Y failures is
3
number of X failures is
0
average trial time
16.036203216249977
mu is
0.005
number of trials is
1000
number of Z or Y failures is
5
number of X failures is
0
average trial time
20.421612671044983
stderr is
0.002231586874844889
target is
0.0005
mu is
0.006666666666666667
number of trials is
1200
number of Z or Y failures is
8
number of X failures is
0
average trial time
24.71280773908997
stderr is
0.002350132149359136
target is
0.0006666666666666668
mu is
0.0064285714285714285
number of trials is
1400
number of Z or Y failures is
9
number of X failures is
0
average trial time
28.843633449224985
stderr is
0.002136721533576821
target is
0.0006428571428571429
mu is
0.00625
number of trials is
1600
number of Z or Y failures is
10
number of X failures is
0
average trial time
33.003397089104936
stderr is
0.001970853521257074
target is
0.0006250000000000001
mu is
0.006666666666666667
number of trials is
1800
number of Z or Y failures is
12
number of X failures is
0
average trial time
37.08113037246492
stderr is
0.0019186081876077336
target is
0.0006666666666666668
mu is
0.006
number of trials is
2000
number of Z or Y failures is
12
number of X failures is
0
average trial time
41.26433374133992
stderr is
0.0017272787111155328
target is
0.0006000000000000001
mu is
0.005454545454545455
number of trials is
2200
number of Z or Y failures is
12
number of X failures is
0
average trial time
45.330618941035
stderr is
0.0015706484365818018
target is
0.0005454545454545455
mu is
0.005833333333333334
number of trials is
2400
number of Z or Y failures is
14
number of X failures is
0
average trial time
49.55338126330503
stderr is
0.0015547940565813873
target is
0.0005833333333333334
mu is
0.0057692307692307696
number of trials is
2600
number of Z or Y failures is
15
number of X failures is
0
average trial time
53.66438508174005
stderr is
0.0014855915330219754
target is
0.000576923076923077
mu is
0.005714285714285714
number of trials is
2800
number of Z or Y failures is
16
number of X failures is
0
average trial time
57.86458664636503
stderr is
0.001424738388584416
target is
0.0005714285714285715
mu is
0.005333333333333333
number of trials is
3000
number of Z or Y failures is
16
number of X failures is
0
average trial time
61.99105048877004
stderr is
0.0013299947086127608
target is
0.0005333333333333334
mu is
0.005
number of trials is
3200
number of Z or Y failures is
16
number of X failures is
0
average trial time
65.94514221896003
stderr is
0.001247065953234295
target is
0.0005
mu is
0.004705882352941176
number of trials is
3400
number of Z or Y failures is
16
number of X failures is
0
average trial time
69.9006003746001
stderr is
0.0011738717986947928
target is
0.0004705882352941176
mu is
0.0044444444444444444
number of trials is
3600
number of Z or Y failures is
16
number of X failures is
0
average trial time
73.83522831994509
stderr is
0.0011087932354671437
target is
0.00044444444444444447
mu is
0.0044736842105263155
number of trials is
3800
number of Z or Y failures is
17
number of X failures is
0
average trial time
77.87413931885511
stderr is
0.0010827405150496262
target is
0.0004473684210526316
The SVD algorithm `"divide_and_conquer"` has thrown an error,
likely because of a convergance failure. You can try
other SVD algorithms that may converge better using the
`alg` (or `svd_alg` if called through `factorize` or MPS/MPO functionality) keyword argument:

 - "divide_and_conquer" is a divide-and-conquer algorithm
   (LAPACK's `gesdd`). It is fast, but may lead to some innacurate
   singular values for very ill-conditioned matrices.
   It also may sometimes fail to converge, leading to errors
   (in which case `"qr_iteration"` or `"recursive"` can be tried).

 - `"qr_iteration"` (LAPACK's `gesvd`) is typically slower 
   than "divide_and_conquer", especially for large matrices,
   but is more accurate for very ill-conditioned matrices 
   compared to `"divide_and_conquer"`.

 - `"recursive"` is ITensor's custom SVD algorithm. It is very
   reliable, but may be slow if high precision is needed.
   To get an `svd` of a matrix `A`, an eigendecomposition of
   ``A^{\dagger} A`` is used to compute `U` and then a `qr` of
   ``A^{\dagger} U`` is used to compute `V`. This is performed
   recursively to compute small singular values.

Returning `nothing`. For an output `F = svd(A, ...)` you can check if
`isnothing(F)` in your code and try a different algorithm.

To suppress this message in the future, you can wrap the `svd` call in the
`@suppress` macro from the `Suppressor` package.

